{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from sklearn.metrics import accuracy_score \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3zVs1K1Y8hp9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IdEejPFF4VJ2"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "n_mfcc = 40;\n",
        "def extract_features(file_path):\n",
        "    audio, sample_rate = librosa.load(file_path, sr = 22050)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
        "    mfccs_mean = pd.DataFrame(mfccs.mean(axis=1)).transpose()\n",
        "    return mfccs_mean\n",
        "\n",
        "\n",
        "def create_dataframe(directory):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for subdir, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = subdir + os.path.sep + file\n",
        "            if file_path.endswith(\".mp3\"):\n",
        "                features = extract_features(file_path)\n",
        "                label = file.split(\".\")[0]\n",
        "                data.append(features)\n",
        "                labels.append(label)\n",
        "    data_df = pd.concat(data, ignore_index=True)\n",
        "    data_df['label'] = labels\n",
        "    return data_df\n",
        "\n",
        "\n",
        "directory = '/content/sample_data/my_audio'\n",
        "data_df = create_dataframe(directory)\n",
        "\n",
        "data_df.to_csv('audio_vectors.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Fqu1HNU57xUN",
        "outputId": "1795df73-d744-47b6-f013-83f19bfb30de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0           1          2          3          4          5  \\\n",
              "0   -310.653198  114.006577  -8.949816  32.298817  23.754930   0.476295   \n",
              "1   -267.643372  144.928879  14.492287   2.945261  10.753216   3.069179   \n",
              "2   -234.778015  124.474327  11.977366  21.836491   8.753133   8.812948   \n",
              "3    -49.295231  126.478638 -19.573408  34.769978  -5.357277  11.110708   \n",
              "4   -162.936539  103.940735  10.802122  17.139130   9.731444 -15.042475   \n",
              "..          ...         ...        ...        ...        ...        ...   \n",
              "238  -72.638695  112.775688  -8.857608  19.901653  -1.954535   8.039962   \n",
              "239 -153.976440  155.608414 -10.307290  29.232224  11.489508  -4.495124   \n",
              "240 -212.141861  117.533676  23.178322  29.083248   7.024023   5.158135   \n",
              "241 -200.818863  128.969162 -17.038839  33.835728   1.757049   6.557553   \n",
              "242 -351.850525  140.470490   3.895830   0.961503   5.067229  10.931565   \n",
              "\n",
              "             6          7          8         9  ...        31        32  \\\n",
              "0    -6.923643  11.022780   0.432234  9.976504  ... -1.674310 -2.337792   \n",
              "1   -11.228010  -2.941697  -6.079162  0.348318  ... -0.334749 -4.377837   \n",
              "2    -1.710792   1.345945  -8.430063  7.340374  ... -1.227019  0.865148   \n",
              "3    -5.309941   3.107733  -7.430996 -2.737630  ...  0.905169 -0.881575   \n",
              "4   -11.973261   4.185050 -16.637585 -0.250949  ... -0.176791 -1.515979   \n",
              "..         ...        ...        ...       ...  ...       ...       ...   \n",
              "238  -4.520589   5.200881  -8.515905  5.033236  ...  1.607350 -0.375451   \n",
              "239  12.960011   1.179408  -8.143290  6.732738  ...  1.575045 -3.600849   \n",
              "240   0.096772   4.927989  -2.399021  3.904829  ...  1.163921 -0.608176   \n",
              "241   0.732583   4.332813  -3.552686  1.173273  ...  0.418746 -4.747782   \n",
              "242  -9.973457   0.674284  -4.597679  6.373856  ... -2.524136 -5.377399   \n",
              "\n",
              "           33        34        35        36        37        38        39  \\\n",
              "0    1.075846 -3.834865  0.333780 -3.112932  0.745917 -0.993104  0.123977   \n",
              "1   -2.721997 -4.408399 -1.734178 -5.442444 -0.920213 -0.754218 -0.292263   \n",
              "2   -0.724218  1.696935  3.195447  3.017133  2.200485 -1.790992 -1.251128   \n",
              "3   -0.870587 -1.651855  0.677101 -1.868641 -0.485206 -3.445559 -0.567956   \n",
              "4    4.082965  0.888164  2.337931 -1.851812 -0.226859 -1.828536 -1.575242   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "238  1.305141 -3.387121  0.278339 -3.015135  1.423900 -2.943631  1.129789   \n",
              "239 -3.099839 -0.748923  0.332382 -2.993572 -0.597006 -1.503161  0.945662   \n",
              "240  2.844276 -0.109941  0.054689 -2.251081 -0.691613 -5.506441 -2.507502   \n",
              "241 -1.278381  0.070128 -0.109303 -2.755774 -2.004298 -1.893307  0.554434   \n",
              "242 -2.181157 -2.697393 -1.986472 -4.307980 -2.024059 -3.314096 -4.257029   \n",
              "\n",
              "     label  \n",
              "0      Sad  \n",
              "1      Sad  \n",
              "2      Sad  \n",
              "3    Angry  \n",
              "4    Happy  \n",
              "..     ...  \n",
              "238  Angry  \n",
              "239    Sad  \n",
              "240    Sad  \n",
              "241  Angry  \n",
              "242  Happy  \n",
              "\n",
              "[243 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75893353-f824-4b49-a423-b61dc15686d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-310.653198</td>\n",
              "      <td>114.006577</td>\n",
              "      <td>-8.949816</td>\n",
              "      <td>32.298817</td>\n",
              "      <td>23.754930</td>\n",
              "      <td>0.476295</td>\n",
              "      <td>-6.923643</td>\n",
              "      <td>11.022780</td>\n",
              "      <td>0.432234</td>\n",
              "      <td>9.976504</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.674310</td>\n",
              "      <td>-2.337792</td>\n",
              "      <td>1.075846</td>\n",
              "      <td>-3.834865</td>\n",
              "      <td>0.333780</td>\n",
              "      <td>-3.112932</td>\n",
              "      <td>0.745917</td>\n",
              "      <td>-0.993104</td>\n",
              "      <td>0.123977</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-267.643372</td>\n",
              "      <td>144.928879</td>\n",
              "      <td>14.492287</td>\n",
              "      <td>2.945261</td>\n",
              "      <td>10.753216</td>\n",
              "      <td>3.069179</td>\n",
              "      <td>-11.228010</td>\n",
              "      <td>-2.941697</td>\n",
              "      <td>-6.079162</td>\n",
              "      <td>0.348318</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.334749</td>\n",
              "      <td>-4.377837</td>\n",
              "      <td>-2.721997</td>\n",
              "      <td>-4.408399</td>\n",
              "      <td>-1.734178</td>\n",
              "      <td>-5.442444</td>\n",
              "      <td>-0.920213</td>\n",
              "      <td>-0.754218</td>\n",
              "      <td>-0.292263</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-234.778015</td>\n",
              "      <td>124.474327</td>\n",
              "      <td>11.977366</td>\n",
              "      <td>21.836491</td>\n",
              "      <td>8.753133</td>\n",
              "      <td>8.812948</td>\n",
              "      <td>-1.710792</td>\n",
              "      <td>1.345945</td>\n",
              "      <td>-8.430063</td>\n",
              "      <td>7.340374</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.227019</td>\n",
              "      <td>0.865148</td>\n",
              "      <td>-0.724218</td>\n",
              "      <td>1.696935</td>\n",
              "      <td>3.195447</td>\n",
              "      <td>3.017133</td>\n",
              "      <td>2.200485</td>\n",
              "      <td>-1.790992</td>\n",
              "      <td>-1.251128</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-49.295231</td>\n",
              "      <td>126.478638</td>\n",
              "      <td>-19.573408</td>\n",
              "      <td>34.769978</td>\n",
              "      <td>-5.357277</td>\n",
              "      <td>11.110708</td>\n",
              "      <td>-5.309941</td>\n",
              "      <td>3.107733</td>\n",
              "      <td>-7.430996</td>\n",
              "      <td>-2.737630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.905169</td>\n",
              "      <td>-0.881575</td>\n",
              "      <td>-0.870587</td>\n",
              "      <td>-1.651855</td>\n",
              "      <td>0.677101</td>\n",
              "      <td>-1.868641</td>\n",
              "      <td>-0.485206</td>\n",
              "      <td>-3.445559</td>\n",
              "      <td>-0.567956</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-162.936539</td>\n",
              "      <td>103.940735</td>\n",
              "      <td>10.802122</td>\n",
              "      <td>17.139130</td>\n",
              "      <td>9.731444</td>\n",
              "      <td>-15.042475</td>\n",
              "      <td>-11.973261</td>\n",
              "      <td>4.185050</td>\n",
              "      <td>-16.637585</td>\n",
              "      <td>-0.250949</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176791</td>\n",
              "      <td>-1.515979</td>\n",
              "      <td>4.082965</td>\n",
              "      <td>0.888164</td>\n",
              "      <td>2.337931</td>\n",
              "      <td>-1.851812</td>\n",
              "      <td>-0.226859</td>\n",
              "      <td>-1.828536</td>\n",
              "      <td>-1.575242</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>-72.638695</td>\n",
              "      <td>112.775688</td>\n",
              "      <td>-8.857608</td>\n",
              "      <td>19.901653</td>\n",
              "      <td>-1.954535</td>\n",
              "      <td>8.039962</td>\n",
              "      <td>-4.520589</td>\n",
              "      <td>5.200881</td>\n",
              "      <td>-8.515905</td>\n",
              "      <td>5.033236</td>\n",
              "      <td>...</td>\n",
              "      <td>1.607350</td>\n",
              "      <td>-0.375451</td>\n",
              "      <td>1.305141</td>\n",
              "      <td>-3.387121</td>\n",
              "      <td>0.278339</td>\n",
              "      <td>-3.015135</td>\n",
              "      <td>1.423900</td>\n",
              "      <td>-2.943631</td>\n",
              "      <td>1.129789</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>-153.976440</td>\n",
              "      <td>155.608414</td>\n",
              "      <td>-10.307290</td>\n",
              "      <td>29.232224</td>\n",
              "      <td>11.489508</td>\n",
              "      <td>-4.495124</td>\n",
              "      <td>12.960011</td>\n",
              "      <td>1.179408</td>\n",
              "      <td>-8.143290</td>\n",
              "      <td>6.732738</td>\n",
              "      <td>...</td>\n",
              "      <td>1.575045</td>\n",
              "      <td>-3.600849</td>\n",
              "      <td>-3.099839</td>\n",
              "      <td>-0.748923</td>\n",
              "      <td>0.332382</td>\n",
              "      <td>-2.993572</td>\n",
              "      <td>-0.597006</td>\n",
              "      <td>-1.503161</td>\n",
              "      <td>0.945662</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>-212.141861</td>\n",
              "      <td>117.533676</td>\n",
              "      <td>23.178322</td>\n",
              "      <td>29.083248</td>\n",
              "      <td>7.024023</td>\n",
              "      <td>5.158135</td>\n",
              "      <td>0.096772</td>\n",
              "      <td>4.927989</td>\n",
              "      <td>-2.399021</td>\n",
              "      <td>3.904829</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163921</td>\n",
              "      <td>-0.608176</td>\n",
              "      <td>2.844276</td>\n",
              "      <td>-0.109941</td>\n",
              "      <td>0.054689</td>\n",
              "      <td>-2.251081</td>\n",
              "      <td>-0.691613</td>\n",
              "      <td>-5.506441</td>\n",
              "      <td>-2.507502</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>-200.818863</td>\n",
              "      <td>128.969162</td>\n",
              "      <td>-17.038839</td>\n",
              "      <td>33.835728</td>\n",
              "      <td>1.757049</td>\n",
              "      <td>6.557553</td>\n",
              "      <td>0.732583</td>\n",
              "      <td>4.332813</td>\n",
              "      <td>-3.552686</td>\n",
              "      <td>1.173273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.418746</td>\n",
              "      <td>-4.747782</td>\n",
              "      <td>-1.278381</td>\n",
              "      <td>0.070128</td>\n",
              "      <td>-0.109303</td>\n",
              "      <td>-2.755774</td>\n",
              "      <td>-2.004298</td>\n",
              "      <td>-1.893307</td>\n",
              "      <td>0.554434</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>-351.850525</td>\n",
              "      <td>140.470490</td>\n",
              "      <td>3.895830</td>\n",
              "      <td>0.961503</td>\n",
              "      <td>5.067229</td>\n",
              "      <td>10.931565</td>\n",
              "      <td>-9.973457</td>\n",
              "      <td>0.674284</td>\n",
              "      <td>-4.597679</td>\n",
              "      <td>6.373856</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.524136</td>\n",
              "      <td>-5.377399</td>\n",
              "      <td>-2.181157</td>\n",
              "      <td>-2.697393</td>\n",
              "      <td>-1.986472</td>\n",
              "      <td>-4.307980</td>\n",
              "      <td>-2.024059</td>\n",
              "      <td>-3.314096</td>\n",
              "      <td>-4.257029</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>243 rows Ã— 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75893353-f824-4b49-a423-b61dc15686d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75893353-f824-4b49-a423-b61dc15686d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75893353-f824-4b49-a423-b61dc15686d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['label'] = data_df['label'].astype(str)"
      ],
      "metadata": {
        "id": "QJY7ed3n9AtX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_counts = data_df['label'].value_counts()\n",
        "sns.barplot(x=emotion_counts.index, y=emotion_counts)\n",
        "plt.title('Count of Emotions', size=16)\n",
        "plt.xlabel('Emotions', size=12)\n",
        "plt.ylabel('Count', size=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "Fpw5GBd472DA",
        "outputId": "c6fae9ec-ae5f-4105-f791-ea86d3de41c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAHNCAYAAAANCzFyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1fklEQVR4nO3deXxNd/7H8fdNZN/siTVCjaXWVKWCUo2GUpS2mLaCFlXVqm50aolSpa21ylBCF7rMTHVRWtQyRbWqGNPKtMbWIbFVYmlEk+/vjz7cn9sEyU3iXl+v5+NxHg/3+/2e7/2ce3KTt3POPddhjDECAACwgI+nCwAAACguBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEG6CYrFy5Uv369dOf/vQnhYeHKyAgQJUqVVL79u01depUHTlyxNMlXnVSUlLUrFkzhYSEyOFwyOFwaO/evZdd7/zYyy1r164t8W0oSee3A8D/K+XpAoCr3dGjR9W7d2+tWrVKklSjRg3dcsstCgkJUVpamjZu3KhVq1Zp9OjRWrVqleLi4jxcceGMHTtWycnJGjNmjMaOHXvFnnfZsmXq37+/AgMDlZCQoHLlykmSQkNDCzxHYmKioqKiLtp/qT5Pa9u2rdatW6c1a9aobdu2ni4HuGoQbIAiyMjIUKtWrZSamqq6detq7ty5at26tcuYs2fPatGiRRozZowOHTrkoUqvPu+//74kacaMGRowYIBbc4wYMcLqUPDDDz94ugTA6xBsgCIYOnSoUlNTVaNGDW3YsEFly5bNMyYgIEADBw5U165ddeLEiStf5FVq//79kqTatWt7uBLvVbduXU+XAHgfA8Atu3fvNr6+vkaS+cc//uH2PEuWLDHt2rUzZcqUMf7+/qZ69eqmX79+JjU1Nd/xksyl3rpt2rQxksyaNWsu2v7dd9+ZO++805QrV874+/ubevXqmZdfftnk5ubm+1z5LUlJSQXextOnT5uJEyeapk2bmtDQUBMUFGTq169v/vKXv5jjx4+7jE1KSiryc54f/8fX4FL27NljJJno6GiTk5Njpk+fbho2bGiCgoJMVFSUGTRokDl27JgxxpisrCwzbtw4U6dOHRMYGGgqVapkHn30UXPq1KmLzl/Q/bxmzZpLvu4pKSl5tjM/x44dMyNHjjT169c3QUFBJjQ01MTGxppJkyaZM2fO5Bl//nnbtGljsrOzzYsvvmjq169vAgMDTdmyZc2dd95pvv/++3yfa8uWLeaee+4xVapUMX5+fiYsLMzExMSY7t27m6VLl17upQeKFcEGcNP06dONJFO6dGnz22+/FXr93Nxc06dPHyPJlCpVyrRr18706tXL/OlPfzKSTHBwsFm+fHme9YoabEaMGOEMM7169TJt2rRxBrTHHnvMZZ2kpCTTuHFjI8k0btzYJCUlOZd58+YVaDuPHTtmmjRpYiSZ8PBw06VLF9OjRw9Tvnx5I8nExMSYPXv2OMfPmzfPJCUlmcjISCPJJCYmFvo5ixpsevfubYKCgkyHDh1Mt27dTMWKFY0k07RpU3Pq1CnTqlUr57Z07tzZREREGEmmY8eOeeYt7H7+4YcfLrr9SUlJ5p///Gee7fyj3bt3m+joaCPJVKhQwfTo0cN06dLFhIWFGUkmNjY2T6A8H2zi4+NNQkKCCQ4ONh06dDA9evQw1apVc/6sX7ivjDFm1apVxs/Pz/kzctddd5k777zTNG/e3AQEBJiuXbsWeB8AxYFgA7jp/vvvN5JMu3bt3Fp/9uzZRpIpX768+e6775ztubm5ZsyYMc4/JIcPH3ZZr6jBRpKZM2eOS9/q1auNw+Ewvr6+5sCBAy5952sZM2aMW9vZs2dPI8nExcWZo0ePOttPnjxpOnbs6PxjWtDtKIiiBBtJplatWmbv3r3OvqNHj5ratWsbSaZhw4amefPmLtvy3//+15QpU8ZIMl9++aXLvO7u54Js/8V+FuLi4owk06VLF5ejSIcPHzaxsbFGkvnzn//sss6FR4qaNm1qDh065Oz79ddfTWJiopFkBg4c6LLeLbfcYiSZt956K08dJ06cMJs2bbpo/UBJINgAburQoYORZHr16uXW+rVq1TKSzIwZM/L05ebmmkaNGhlJZsKECS59RQ023bt3z3e989vzxhtvuLQXJdjs27fP+Pj4GIfDYbZv356n/+effzaBgYFGktmwYUOBtqMgLnUq5/wSERHhss6FwWbZsmV55pwyZYqRZBwOh/nXv/6Vp3/o0KFGkklOTnZpd3c/uxts/vnPfzqPBKWlpeVZZ8uWLUaS8fHxcQmx54ONw+Ew27Zty7PeV199ZSSZmjVrurTXr1/fSMpzBAjwFO5jA3jAzz//rN27d0uSkpKS8vQ7HA7169dPkrRmzZpife477rgj3/Z69epJkv73v/8V23OtX79eubm5atq0qRo1apSnv0qVKkpMTJRU/Nsp/f5x76SkpHyXP//5z/muU6pUKd1222152s9fxFy9enU1aNDgov0HDx50tnliP5+/N0+HDh0UGRmZp/+GG25Q48aNlZubq3Xr1uXpr169uho3bpyn/WI/H82bN5ck3Xvvvfryyy/122+/FXUTgCLhU1GAmypUqCBJOnz4cKHXPf/HoVy5cgoPD893TK1atVzGFpfq1avn236+jqysrGJ7rvO1x8TEXHRMSW2n5N7HvStVqqRSpfL+ajx//5yLvX5hYWGSXF8/T+zngr7m27dvz/c5L/fzcfbsWZf2iRMnaseOHVq+fLmWL1+uoKAgxcbGqm3btrr33nudgQi4UjhiA7jphhtukCRt3bpVOTk5Hq7m/+Xm5l6y38eHt/2lXO71sf31K+z2RUVFacuWLVqzZo3+8pe/KC4uTlu3btWECRN0/fXXa9KkSSVUKZA/u9+hQAnq3LmzfHx8dOLECX300UeFWrdKlSqSpGPHjikzMzPfMf/9739dxp7n5+cnSTp58mS+6+3bt69QtZSk87Wf35b8XGw7bVCU/VzU57ySr7nD4VDbtm01fvx4rVmzRsePH9fs2bPlcDj07LPPOk/HAVcCwQZwU61atdS7d29J0hNPPKHjx49fcvzhw4eVmpoqSapatarzFMTChQvzjDXGONtvueUWl77zf4zyu+vsjh07dODAgUJtx+X4+/tLklvXTtx8883y8fHRtm3btH379jz9hw4d0ooVKyTl3U4bFGU/u/u6nz/1tmLFCqWnp+fp/+6777Rt2zb5+Pjo5ptvLtTcBRUYGKiHHnpIjRo1Um5urnbs2FEizwPkh2ADFMHMmTN13XXXac+ePWrVqpW+/PLLPGOys7O1YMECNW3a1CWMPPnkk5Kk559/3uWPvjFG48eP17Zt21S6dOk8XyeQkJAgSUpOTna53mHv3r1KSkqSMaZYt7Fq1aqSpH//+9+FXrd69eq6++67ZYzRoEGDdOzYMWff6dOnNXDgQGVlZSk+Pl7x8fHFVrM3cXc/u/u6t2rVSnFxcfr11181aNAgnTlzxtl39OhRDRo0SJLUq1cvVatWza1tutDLL7/svEv0hXbt2qUff/xRkhQdHV3k5wEKiouHgSIoU6aMNmzYoJ49e2rt2rVq3bq1YmJi1KhRIwUHBys9PV1ff/21Tp06pfDwcFWuXNm57qBBg7Rx40a9+eabatasmdq0aaOKFStq69atSk1NVVBQkBYvXuy8SPm8Z599Vn/729/06aef6k9/+pNuvPFGHTlyRN98841atmyp+Ph4bdy4sdi2MTExUSEhIVq6dKlatWql2rVry9fXVy1btnR+oudSZs2apV27dmnz5s2qVauWbrnlFpUqVUrr1q3TkSNHFBMTo7fffrvY6r3Qiy++mO+RkvP+/Oc/5/sJqOLk7n7u0aOHUlJS9PTTT2vVqlWqWLGiHA6H+vfvf9kQuHjxYrVr104ffvihYmJidPPNN+vcuXNas2aNMjMzFRsbq1dffbVYtm/8+PF66qmnVLduXdWrV09BQUE6ePCg8xNSffr0UWxsbLE8F1AgnvysOWCT5cuXmz59+pjrrrvOhIaGGj8/PxMVFWXat29vpk2b5rwd/x8tXrzYtG3b1pQuXdr4+fmZatWqmb59+5pdu3Zd9Lm+//570717d1OmTBkTEBBg6tSpY8aPH2+ys7ML9JUK+bnU/WrWr19vEhISTJkyZYyPj4/bX6nQpEkTExwcbAIDA029evXMs88+e9H7n5T0fWwkmalTpzrXufDOw/m58CsH8pOSknLJ18Wd/Txv3jwTGxtrgoOD3f5KhXr16pnAwEATHBxsmjZtal588cXLfqXCxeT3fG+99Zbp16+fadCggSlbtqwJCAgw0dHRpmPHjuaDDz7I8zUdQElzGFPMx60BAAA8hGtsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACscc3doC83N1cHDx5UWFiYHA6Hp8sBAAAFYIzRyZMnVbly5Ut+Wes1F2wOHjxYLLcRBwAAV96BAwecXzmSn2su2ISFhUn6/YUJDw/3cDUAAKAgMjMzVa1aNeff8Yu55oLN+dNP4eHhBBsAAK4yl7uMhIuHAQCANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYo5ekCrgY3PPWGp0vABb59qY+nSwAAeCmO2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANrwo2OTk5GjVqlGJiYhQUFKRatWrp+eeflzHGOcYYo9GjR6tSpUoKCgpSQkKCfvzxRw9WDQAAvIVXBZtJkyZp9uzZevXVV/XDDz9o0qRJmjx5smbOnOkcM3nyZM2YMUNz5szR5s2bFRISosTERGVlZXmwcgAA4A1KebqAC23cuFFdu3ZVp06dJEk1atTQkiVL9PXXX0v6/WjNtGnT9Nxzz6lr166SpDfeeEORkZFaunSpevXq5bHaAQCA53nVEZv4+HitXr1a//nPfyRJ27dv15dffqmOHTtKkvbs2aO0tDQlJCQ414mIiFBcXJw2bdqU75xnz55VZmamywIAAOzkVUdsRowYoczMTNWtW1e+vr7KycnRhAkTdO+990qS0tLSJEmRkZEu60VGRjr7/mjixIlKTk4u2cIBAIBX8KojNu+9957efvttLV68WFu3btWiRYv08ssva9GiRW7POXLkSGVkZDiXAwcOFGPFAADAm3jVEZunnnpKI0aMcF4r07BhQ+3bt08TJ05UUlKSoqKiJEnp6emqVKmSc7309HQ1adIk3zkDAgIUEBBQ4rUDAADP86ojNmfOnJGPj2tJvr6+ys3NlSTFxMQoKipKq1evdvZnZmZq8+bNatGixRWtFQAAeB+vOmJzxx13aMKECapevbquv/56fffdd5oyZYr69+8vSXI4HBo2bJjGjx+v2rVrKyYmRqNGjVLlypXVrVs3zxYPAAA8zquCzcyZMzVq1Cg9/PDDOnz4sCpXrqxBgwZp9OjRzjFPP/20Tp8+rYEDB+rEiRNq1aqVVqxYocDAQA9WDgAAvIHDXHhb32tAZmamIiIilJGRofDw8AKtc8NTb5RwVSiMb1/q4+kSAABXWEH/fnvVNTYAAABFQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwRilPFwB4m/3jGnq6BFyg+uh/eboEAFcRjtgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANUp5ugAA8KSWM1t6ugRcYMPQDZ4uAVc5jtgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwhtcFm//973+67777VK5cOQUFBalhw4basmWLs98Yo9GjR6tSpUoKCgpSQkKCfvzxRw9WDAAAvIVXBZtffvlFLVu2lJ+fn5YvX67vv/9er7zyisqUKeMcM3nyZM2YMUNz5szR5s2bFRISosTERGVlZXmwcgAA4A1KebqAC02aNEnVqlVTSkqKsy0mJsb5b2OMpk2bpueee05du3aVJL3xxhuKjIzU0qVL1atXryteMwAA8B5edcTmo48+UrNmzXT33XerYsWKatq0qebNm+fs37Nnj9LS0pSQkOBsi4iIUFxcnDZt2uSJkgEAgBfxqmDz3//+V7Nnz1bt2rX12WefafDgwXr00Ue1aNEiSVJaWpokKTIy0mW9yMhIZ98fnT17VpmZmS4LAACwk1edisrNzVWzZs30wgsvSJKaNm2qnTt3as6cOUpKSnJrzokTJyo5Obk4ywQAAF7Kq47YVKpUSfXr13dpq1evnvbv3y9JioqKkiSlp6e7jElPT3f2/dHIkSOVkZHhXA4cOFAClQMAAG/gVcGmZcuWSk1NdWn7z3/+o+joaEm/X0gcFRWl1atXO/szMzO1efNmtWjRIt85AwICFB4e7rIAAAA7edWpqMcff1zx8fF64YUXdM899+jrr7/W3LlzNXfuXEmSw+HQsGHDNH78eNWuXVsxMTEaNWqUKleurG7dunm2eAAA4HFeFWxuvPFGffDBBxo5cqTGjRunmJgYTZs2Tffee69zzNNPP63Tp09r4MCBOnHihFq1aqUVK1YoMDDQg5UDAABv4FXBRpI6d+6szp07X7Tf4XBo3LhxGjdu3BWsCgAAXA286hobAACAoiDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALCG28GmXbt2Wr169UX716xZo3bt2rk7PQAAQKG5HWzWrl2r9PT0i/YfPnxY69atc3d6AACAQivSqSiHw3HRvp9++klhYWFFmR4AAKBQShVm8KJFi7Ro0SLn4/Hjx2vevHl5xp04cUI7duzQ7bffXvQKAQAACqhQwebMmTM6cuSI8/HJkyfl4+N60MfhcCgkJEQPPfSQRo8eXTxVAgAAFEChgs3gwYM1ePBgSVJMTIymT5+uLl26lEhhAAAAhVWoYHOhPXv2FGcdAAAAReZ2sDnv5MmT2rdvn3755RcZY/L033zzzUV9CgAAgAJxO9gcPXpUQ4cO1d///nfl5OTk6TfGyOFw5NsHAABQEtwONgMHDtTHH3+sRx99VK1bt1aZMmWKsy4AAIBCczvYfP7553r88cc1efLk4qwHAADAbW7foC84OFg1atQoxlIAAACKxu1gc9999+mDDz4ozloAAACKxO1TUXfddZfWrVunDh06aODAgapWrZp8fX3zjIuNjS1SgQAAAAXldrBp1aqV898rV67M08+nogAAwJXmdrBJSUkpzjoAAACKzO1gk5SUVJx1AAAAFJnbFw8DAAB4G7eP2PTv3/+yYxwOh+bPn+/uUwAAABSK28Hmiy++kMPhcGnLycnRoUOHlJOTowoVKigkJKTIBQIAABSU28Fm7969+bafO3dOf/3rXzVt2rR8Py0FAABQUor9Ghs/Pz898sgjuu222/TII48U9/QAAAAXVWIXDzdu3Fjr168vqekBAADyKLFgs3LlSgUHB5fU9AAAAHm4fY3NuHHj8m0/ceKE1q9fr61bt2rEiBFuFwYAAFBYbgebsWPH5ttepkwZ1apVS3PmzNGAAQPcnR4AAKDQ3A42ubm5xVkHAABAkXHnYQAAYA23j9ict27dOi1btkz79u2TJEVHR6tTp05q06ZNkYsDAAAoDLeDTXZ2tnr37q2lS5fKGKPSpUtL+v3i4VdeeUV33nmnlixZIj8/v+KqFQAA4JLcPhWVnJysDz74QE888YQOHTqk48eP6/jx40pLS9OTTz6pf/zjHxf95BQAAEBJcDvYLF68WElJSZo8ebIiIyOd7RUrVtSkSZPUp08fvfnmm8VSJAAAQEG4HWwOHTqkuLi4i/bHxcUpLS3N3ekBAAAKze1gU7VqVa1du/ai/evWrVPVqlXdnR4AAKDQ3A42SUlJeu+99/TQQw8pNTVVOTk5ys3NVWpqqgYPHqz3339fffv2LcZSAQAALs3tT0U9++yz2r17t+bOnat58+bJx+f3jJSbmytjjJKSkvTss88WW6EAAACX43aw8fX11cKFCzV8+HB9+umnLvexuf3229WoUaNiKxIAAKAgChVssrKyNGzYMF1//fUaOnSoJKlRo0Z5QsyMGTM0Z84cTZ8+nfvYAACAK6ZQ19jMnTtXCxcuVKdOnS45rlOnTlqwYIFef/31IhUHAABQGIUKNu+995569OihmjVrXnJcrVq1dPfdd2vJkiVFKg4AAKAwChVs/vWvf6lVq1YFGhsfH68dO3a4VRQAAIA7ChVssrOz5e/vX6Cx/v7+Onv2rFtFAQAAuKNQwaZy5crauXNngcbu3LlTlStXdqsoAAAAdxQq2CQkJOiNN97Q4cOHLznu8OHDeuONN9S+ffsiFQcAAFAYhQo2zzzzjLKystSuXTtt3rw53zGbN2/WrbfeqqysLD311FPFUiQAAEBBFOo+NjVr1tR7772n3r17Kz4+XjVr1lTDhg0VFhamkydPaufOndq9e7eCg4P1zjvvqFatWiVVNwAAQB6FvvNwp06dtGPHDk2aNEmffPKJli5d6uyrXLmyBgwYoKeffvqyHwkHAAAobm59pUKNGjU0e/ZszZ49WydPnlRmZqbCw8MVFhZW3PUBAAAUmNvfFXVeWFgYgQYAAHiFQl08DAAA4M0INgAAwBpeG2xefPFFORwODRs2zNmWlZWlIUOGqFy5cgoNDVWPHj2Unp7uuSIBAIBX8cpg88033+ivf/2rGjVq5NL++OOP6+OPP9b777+vdevW6eDBg+revbuHqgQAAN7G64LNqVOndO+992revHkqU6aMsz0jI0Pz58/XlClT1K5dO91www1KSUnRxo0b9dVXX3mwYgAA4C28LtgMGTJEnTp1UkJCgkv7t99+q3Pnzrm0161bV9WrV9emTZsuOt/Zs2eVmZnpsgAAADsV+ePexemdd97R1q1b9c033+TpS0tLk7+/v0qXLu3SHhkZqbS0tIvOOXHiRCUnJxd3qQAAwAt5zRGbAwcO6LHHHtPbb7+twMDAYpt35MiRysjIcC4HDhwotrkBAIB38Zpg8+233+rw4cOKjY1VqVKlVKpUKa1bt04zZsxQqVKlFBkZqezsbJ04ccJlvfT0dEVFRV103oCAAIWHh7ssAADATl5zKurWW2/Vv/71L5e2fv36qW7dunrmmWdUrVo1+fn5afXq1erRo4ckKTU1Vfv371eLFi08UTIAAPAyXhNswsLC1KBBA5e2kJAQlStXztn+wAMPaPjw4SpbtqzCw8M1dOhQtWjRQjfddJMnSgYAAF7Ga4JNQUydOlU+Pj7q0aOHzp49q8TERL322mueLgsAAHgJrw42a9eudXkcGBioWbNmadasWZ4pCAAAeDWvuXgYAACgqAg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDW8KthMnDhRN954o8LCwlSxYkV169ZNqampLmOysrI0ZMgQlStXTqGhoerRo4fS09M9VDEAAPAmXhVs1q1bpyFDhuirr77SypUrde7cOd122206ffq0c8zjjz+ujz/+WO+//77WrVungwcPqnv37h6sGgAAeItSni7gQitWrHB5vHDhQlWsWFHffvutbr75ZmVkZGj+/PlavHix2rVrJ0lKSUlRvXr19NVXX+mmm27yRNkAAMBLeNURmz/KyMiQJJUtW1aS9O233+rcuXNKSEhwjqlbt66qV6+uTZs25TvH2bNnlZmZ6bIAAAA7eW2wyc3N1bBhw9SyZUs1aNBAkpSWliZ/f3+VLl3aZWxkZKTS0tLynWfixImKiIhwLtWqVSvp0gEAgId4bbAZMmSIdu7cqXfeeadI84wcOVIZGRnO5cCBA8VUIQAA8DZedY3NeY888og++eQTrV+/XlWrVnW2R0VFKTs7WydOnHA5apOenq6oqKh85woICFBAQEBJlwwAALyAVx2xMcbokUce0QcffKAvvvhCMTExLv033HCD/Pz8tHr1amdbamqq9u/frxYtWlzpcgEAgJfxqiM2Q4YM0eLFi/Xhhx8qLCzMed1MRESEgoKCFBERoQceeEDDhw9X2bJlFR4erqFDh6pFixZ8IgoAAHhXsJk9e7YkqW3bti7tKSkp6tu3ryRp6tSp8vHxUY8ePXT27FklJibqtddeu8KVAgAAb+RVwcYYc9kxgYGBmjVrlmbNmnUFKgIAAFcTr7rGBgAAoCgINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYI1Sni4AAIArZd3NbTxdAi7QZv26Yp+TIzYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWOOqDDazZs1SjRo1FBgYqLi4OH399deeLgkAAHiBqy7YvPvuuxo+fLjGjBmjrVu3qnHjxkpMTNThw4c9XRoAAPCwqy7YTJkyRQMGDFC/fv1Uv359zZkzR8HBwVqwYIGnSwMAAB52VQWb7Oxsffvtt0pISHC2+fj4KCEhQZs2bfJgZQAAwBuU8nQBhXH06FHl5OQoMjLSpT0yMlK7du3Kd52zZ8/q7NmzzscZGRmSpMzMzAI/b87ZX92oFiWlMPvOHSezckp0fhROSe/v3379rUTnR+GU9P4+/Rv725sUZn+fH2uMueS4qyrYuGPixIlKTk7O016tWjUPVIPiEDHzIU+XgCtpYoSnK8AVFPEM+/uaElH4/X3y5ElFXGK9qyrYlC9fXr6+vkpPT3dpT09PV1RUVL7rjBw5UsOHD3c+zs3N1fHjx1WuXDk5HI4SrdebZGZmqlq1ajpw4IDCw8M9XQ5KGPv72sL+vrZcq/vbGKOTJ0+qcuXKlxx3VQUbf39/3XDDDVq9erW6desm6fegsnr1aj3yyCP5rhMQEKCAgACXttKlS5dwpd4rPDz8mnojXOvY39cW9ve15Vrc35c6UnPeVRVsJGn48OFKSkpSs2bN1Lx5c02bNk2nT59Wv379PF0aAADwsKsu2PTs2VNHjhzR6NGjlZaWpiZNmmjFihV5LigGAADXnqsu2EjSI488ctFTT8hfQECAxowZk+e0HOzE/r62sL+vLezvS3OYy31uCgAA4CpxVd2gDwAA4FIINgAAwBoEGwAAYA2CDXCNW7hw4TV9bycAdiHYXAU2bdokX19fderUydOlwMOOHDmiwYMHq3r16goICFBUVJQSExO1YcMGT5eGQujbt6/zJqMXWrt2rRwOh06cOHHFa4Jn9O3bVw6HI8/y008/ebq0q9ZV+XHva838+fM1dOhQzZ8/XwcPHrzs7aSLKjs7W/7+/iX6HHBPjx49lJ2drUWLFqlmzZpKT0/X6tWrdezYMU+XBsBNHTp0UEpKiktbhQoViv15cnJy5HA45ONj9zENu7fOAqdOndK7776rwYMHq1OnTlq4cKGz7/z/7lavXq1mzZopODhY8fHxSk1NdZlj/PjxqlixosLCwvTggw9qxIgRatKkibP//P8eJ0yYoMqVK6tOnToaN26cGjRokKeeJk2aaNSoUSW1ubiEEydO6J///KcmTZqkW265RdHR0WrevLlGjhypLl26SJKmTJmihg0bKiQkRNWqVdPDDz+sU6dOucyzcOFCVa9eXcHBwbrzzjsJRV7q2LFj6t27t6pUqaLg4GA1bNhQS5YscRnTtm1b5329IiIiVL58eY0aNcrl249r1Kih559/Xr1791ZISIiqVKmiWbNmOfv79++vzp07u8x77tw5VaxYUfPnzy/ZjYQkOY++Xrj4+vrqww8/VGxsrAIDA1WzZk0lJyfrtwu+nfxy7/fzp5k/+ugj1a9fXwEBAdq/f78nNvHKMvBq8+fPN82aNTPGGPPxxx+bWrVqmdzcXGOMMWvWrDGSTFxcnFm7dq3597//bVq3bm3i4+Od67/11lsmMDDQLFiwwKSmpprk5GQTHh5uGjdu7ByTlJRkQkNDzf3332927txpdu7caQ4cOGB8fHzM119/7Ry3detW43A4zO7du6/MxsPFuXPnTGhoqBk2bJjJysrKd8zUqVPNF198Yfbs2WNWr15t6tSpYwYPHuzs/+qrr4yPj4+ZNGmSSU1NNdOnTzelS5c2ERERV2grYMzv77muXbvmaT//nv7ll1/Mzz//bF566SXz3Xffmd27d5sZM2YYX19fs3nzZuf4Nm3amNDQUPPYY4+ZXbt2mbfeessEBwebuXPnOsdER0ebsLAwM3HiRJOamuqc5/PPPzfGGLNhwwbj6+trDh486FznH//4hwkJCTEnT54suRcBxpiL/yysX7/ehIeHm4ULF5rdu3ebzz//3NSoUcOMHTvWOeZy7/eUlBTj5+dn4uPjzYYNG8yuXbvM6dOnr8RmeRTBxsvFx8ebadOmGWN+/8NWvnx5s2bNGmPM//8SXLVqlXP8smXLjCTz66+/GmOMiYuLM0OGDHGZs2XLlnmCTWRkpDl79qzLuI4dO7q8SYYOHWratm1bnJuHQvrb3/5mypQpYwIDA018fLwZOXKk2b59+0XHv//++6ZcuXLOx7179za33367y5iePXsSbK6wpKQk4+vra0JCQlyWwMBAZ7DJT6dOncwTTzzhfNymTRtTr1495392jDHmmWeeMfXq1XM+jo6ONh06dHCZp2fPnqZjx47Ox/Xr1zeTJk1yPr7jjjtM3759i7qZKID8fhbuuusuc+utt5oXXnjBZeybb75pKlWqdNG5/vh+T0lJMZLMtm3bSqx+b8SpKC+Wmpqqr7/+Wr1795YklSpVSj179sxzeLhRo0bOf1eqVEmSdPjwYecczZs3dxn/x8eS1LBhwzzX1QwYMEBLlixRVlaWsrOztXjxYvXv37/oGwa39ejRQwcPHtRHH32kDh06aO3atYqNjXWeoly1apVuvfVWValSRWFhYbr//vt17NgxnTlzRpL0ww8/KC4uzmXOFi1aXOnNgKRbbrlF27Ztc1lef/11Z39OTo6ef/55NWzYUGXLllVoaKg+++yzPKcSbrrpJjkcDufjFi1a6Mcff1ROTo5L24VatGihH374wfn4wQcfdF7jkZ6eruXLl/Nev4L++LMwY8YMbd++XePGjVNoaKhzGTBggA4dOuR8P1/u/S5J/v7+Ln8jrgVcPOzF5s+fr99++83lYmFjjAICAvTqq6862/z8/Jz/Pv8LLjc3t1DPFRISkqftjjvuUEBAgD744AP5+/vr3Llzuuuuuwq7GShmgYGBat++vdq3b69Ro0bpwQcf1JgxY9S2bVt17txZgwcP1oQJE1S2bFl9+eWXeuCBB5Sdna3g4GBPl44LhISE6LrrrnNp+/nnn53/fumllzR9+nRNmzbNeR3FsGHDlJ2dXey19OnTRyNGjNCmTZu0ceNGxcTEqHXr1sX+PMhffj8Lp06dUnJysrp3755nfGBgoPbu3Vug93tQUJBL8L0WEGy81G+//aY33nhDr7zyim677TaXvm7dumnJkiWqW7fuZeepU6eOvvnmG/Xp08fZ9s033xSohlKlSikpKUkpKSny9/dXr169FBQUVLgNQYmrX7++li5dqm+//Va5ubl65ZVXnJ96eO+991zG1qtXT5s3b3Zp++qrr65YrSi4DRs2qGvXrrrvvvsk/f6flf/85z+qX7++y7j89mft2rXl6+vr0vbHMfXq1XM+LleunLp166aUlBRt2rRJ/fr1K+7NQSHFxsYqNTU1T+A5ryDv92sVwcZLffLJJ/rll1/0wAMPKCIiwqWvR48emj9/vl566aXLzjN06FANGDBAzZo1U3x8vN59913t2LFDNWvWLFAdDz74oPMXIPdK8axjx47p7rvvVv/+/dWoUSOFhYVpy5Ytmjx5srp27arrrrtO586d08yZM3XHHXdow4YNmjNnjsscjz76qFq2bKmXX35ZXbt21WeffaYVK1Z4aItwKbVr19bf/vY3bdy4UWXKlNGUKVOUnp6eJ9js379fw4cP16BBg7R161bNnDlTr7zyisuYDRs2aPLkyerWrZtWrlyp999/X8uWLXMZ8+CDD6pz587KyclRUlJSiW8fLm306NHq3Lmzqlevrrvuuks+Pj7avn27du7cqfHjxxfo/X6t4hobLzV//nwlJCTkCTXS78Fmy5Yt2rFjx2XnuffeezVy5Eg9+eSTio2N1Z49e9S3b18FBgYWqI7atWsrPj5edevWzXNtBq6s0NBQxcXFaerUqbr55pvVoEEDjRo1SgMGDNCrr76qxo0ba8qUKZo0aZIaNGigt99+WxMnTnSZ46abbtK8efM0ffp0NW7cWJ9//rmee+45D20RLuW5555TbGysEhMT1bZtW0VFReV7U78+ffro119/VfPmzTVkyBA99thjGjhwoMuYJ554Qlu2bFHTpk01fvx4TZkyRYmJiS5jEhISVKlSJSUmJpb4vbJweYmJifrkk0/0+eef68Ybb9RNN92kqVOnKjo6WpIK9H6/VjmMueCGB7gmtG/fXlFRUXrzzTcvO9YYo9q1a+vhhx/W8OHDr0B1AAqqbdu2atKkiaZNm3bRMTVq1NCwYcM0bNiwS8516tQpValSRSkpKfle1wFcLTgVZbkzZ85ozpw5SkxMlK+vr5YsWaJVq1Zp5cqVl133yJEjeuedd5SWlsY5d8BSubm5Onr0qF555RWVLl3aebNH4GpFsLGcw+HQp59+qgkTJigrK0t16tTR3//+dyUkJFx23YoVK6p8+fKaO3euypQpcwWqBXCl7d+/XzExMapataoWLlyoUqX4s4CrG6eiAACANbh4GAAAWINgAwAArEGwAQAA1iDYAAAAaxBsAFhv7969cjgczi8LBWAvgg0Aty1cuFAOh+Oiy5X+HqrFixdf8mZ1AOzHDQsAFNm4ceMUExOTp/1iX+BXUhYvXqydO3fmuctudHS0fv31V/n5+V3RegBceQQbAEXWsWNHNWvWzNNlXJTD4Sjw96MBuLpxKgpAiTp/fcvLL7+sWbNmqWbNmgoODtZtt92mAwcOyBij559/XlWrVlVQUJC6du2q48eP55nntdde0/XXX6+AgABVrlxZQ4YM0YkTJ5z9bdu21bJly7Rv3z7nqbAaNWq41PDHa2y++OILtW7dWiEhISpdurS6du2qH374wWXM2LFj5XA49NNPP6lv374qXbq0IiIi1K9fP505c8Zl7MqVK9WqVSuVLl1aoaGhqlOnjp599tlieR0BFAxHbAAUWUZGho4ePerS5nA4VK5cOefjt99+W9nZ2Ro6dKiOHz+uyZMn65577lG7du20du1aPfPMM/rpp580c+ZMPfnkk1qwYIFz3bFjxyo5OVkJCQkaPHiwUlNTNXv2bH3zzTfasGGD/Pz89Je//EUZGRn6+eefNXXqVEm/fyP6xaxatUodO3ZUzZo1NXbsWP3666+aOXOmWrZsqa1btzpD0Xn33HOPYmJiNHHiRG3dulWvv/66KlasqEmTJkmS/v3vf6tz585q1KiRxo0bp4CAAP3000/asGFDUV9eAIVhAMBNKSkpRlK+S0BAgDHGmD179hhJpkKFCubEiRPOdUeOHGkkmcaNG5tz584523v37m38/f1NVlaWMcaYw4cPG39/f3PbbbeZnJwc57hXX33VSDILFixwtnXq1MlER0fnqfN8DSkpKc62Jk2amIoVK5pjx44527Zv3258fHxMnz59nG1jxowxkkz//v1d5rzzzjtNuXLlnI+nTp1qJJkjR44U9OUDUAI4FQWgyGbNmqWVK1e6LMuXL3cZc/fddysiIsL5OC4uTpJ03333uXzxYlxcnLKzs/W///1P0u9HVrKzszVs2DD5+Pz/r6wBAwYoPDxcy5YtK3S9hw4d0rZt29S3b1+VLVvW2d6oUSO1b99en376aZ51HnroIZfHrVu31rFjx5SZmSlJKl26tCTpww8/VG5ubqFrAlA8OBUFoMiaN29+2YuHq1ev7vL4fMipVq1avu2//PKLJGnfvn2SpDp16riM8/f3V82aNZ39hXGxOSWpXr16+uyzz3T69GmFhIRctP7z33j/yy+/KDw8XD179tTrr7+uBx98UCNGjNCtt96q7t2766677nIJZABKFu82AFeEr69vodqNMSVZTqFdrs6goCCtX79eq1at0v33368dO3aoZ8+eat++vXJycq5kqcA1jWADwKtFR0dLklJTU13as7OztWfPHme/9PsFy0WZU5J27dql8uXLuxytKSgfHx/deuutmjJlir7//ntNmDBBX3zxhdasWVPouQC4h2ADwKslJCTI399fM2bMcDmKM3/+fGVkZKhTp07OtpCQEGVkZFx2zkqVKqlJkyZatGiRy0fGd+7cqc8//1y33357oevM7yPqTZo0kSSdPXu20PMBcA/X2AAosuXLl2vXrl152uPj44t8fUmFChU0cuRIJScnq0OHDurSpYtSU1P12muv6cYbb9R9993nHHvDDTfo3Xff1fDhw3XjjTcqNDRUd9xxR77zvvTSS+rYsaNatGihBx54wPlx74iICI0dO7bQdY4bN07r169Xp06dFB0drcOHD+u1115T1apV1apVK3c3H0AhEWwAFNno0aPzbU9JSVHbtm2LPP/YsWNVoUIFvfrqq3r88cdVtmxZDRw4UC+88ILL1yQ8/PDD2rZtm1JSUjR16lRFR0dfNNgkJCRoxYoVGjNmjEaPHi0/Pz+1adNGkyZNyvfrIS6nS5cu2rt3rxYsWKCjR4+qfPnyatOmjZKTk10+DQagZDmMt12hBwAA4CausQEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgjf8DBUjs1FdSE8IAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_waveplot(data, sr, e):\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n",
        "    librosa.display.waveplot(data, sr=sr)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def create_spectrogram(data, sr, e):\n",
        "    X = librosa.stft(data)\n",
        "    Xdb = librosa.amplitude_to_db(abs(X))\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
        "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
        "    plt.colorbar()\n"
      ],
      "metadata": {
        "id": "4NzST5Zx9Lhj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion='Angry'\n",
        "path = np.array(data_df.Path[data_df.Label==emotion])[1]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "create_waveplot(data, sampling_rate, emotion)\n",
        "create_spectrogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "nnxNTOxU9umy",
        "outputId": "615b1d1d-a0be-4612-f2c5-e42de294759b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1afb6bd306c6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Angry'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcreate_waveplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcreate_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Path'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XX = data_df.drop('label', axis=1)\n",
        "data_df['label'] = data_df['label'].replace({'Angry': 0, 'Sad': 1, 'Happy': 2,'Fear': 3})\n",
        "YY = data_df['label']\n",
        "x = XX.values\n",
        "y = YY.values\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "y = encoder.fit_transform(np.array(y).reshape(-1,1)).toarray()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAoDDRWb_jWT",
        "outputId": "7fea91be-8bee-41e5-9aa9-a58f333c525f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((145, 40), (145, 4), (49, 40), (49, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "vtchQgcVJJFU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(40,1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(128, kernel_size=3,strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZM9qBesMBK7",
        "outputId": "702eb40c-643c-45c2-8fcf-bb9ad524a14f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_56 (Conv1D)          (None, 38, 32)            128       \n",
            "                                                                 \n",
            " max_pooling1d_41 (MaxPoolin  (None, 19, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_57 (Conv1D)          (None, 17, 64)            6208      \n",
            "                                                                 \n",
            " max_pooling1d_42 (MaxPoolin  (None, 8, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_58 (Conv1D)          (None, 6, 128)            24704     \n",
            "                                                                 \n",
            " max_pooling1d_43 (MaxPoolin  (None, 3, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 384)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 256)               98560     \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,628\n",
            "Trainable params: 130,628\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
        "history=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUjEvYmRMMzO",
        "outputId": "44f6934d-cbda-47b5-9b4c-3f34c921484e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 3s 133ms/step - loss: 1.3577 - accuracy: 0.3793 - val_loss: 1.2944 - val_accuracy: 0.3061 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.2381 - accuracy: 0.4690 - val_loss: 1.2304 - val_accuracy: 0.3265 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.2046 - accuracy: 0.4759 - val_loss: 1.2285 - val_accuracy: 0.3061 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.1972 - accuracy: 0.4966 - val_loss: 1.2601 - val_accuracy: 0.3061 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.1722 - accuracy: 0.5310 - val_loss: 1.2441 - val_accuracy: 0.3878 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.1132 - accuracy: 0.5310 - val_loss: 1.2094 - val_accuracy: 0.3878 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.0685 - accuracy: 0.5793 - val_loss: 1.1551 - val_accuracy: 0.4082 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.0628 - accuracy: 0.5724 - val_loss: 1.1325 - val_accuracy: 0.4490 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.0598 - accuracy: 0.5931 - val_loss: 1.1572 - val_accuracy: 0.4490 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.0237 - accuracy: 0.5724 - val_loss: 1.1506 - val_accuracy: 0.4286 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.0239 - accuracy: 0.6000 - val_loss: 1.1686 - val_accuracy: 0.4286 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.9434 - accuracy: 0.6621 - val_loss: 1.1495 - val_accuracy: 0.3878 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9595 - accuracy: 0.6759 - val_loss: 1.1113 - val_accuracy: 0.4286 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.9401 - accuracy: 0.6552 - val_loss: 1.1297 - val_accuracy: 0.4694 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.8945 - accuracy: 0.6759 - val_loss: 1.1548 - val_accuracy: 0.4286 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.8519 - accuracy: 0.6759 - val_loss: 1.1192 - val_accuracy: 0.4490 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8079 - accuracy: 0.7448 - val_loss: 1.1162 - val_accuracy: 0.4694 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.7871 - accuracy: 0.7034 - val_loss: 1.0689 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.7676 - accuracy: 0.7310 - val_loss: 1.0585 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6988 - accuracy: 0.7586 - val_loss: 1.1599 - val_accuracy: 0.4082 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.6969 - accuracy: 0.7517 - val_loss: 1.1499 - val_accuracy: 0.4286 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.6479 - accuracy: 0.8069 - val_loss: 1.0233 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6409 - accuracy: 0.7862 - val_loss: 1.0141 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5742 - accuracy: 0.8069 - val_loss: 1.1575 - val_accuracy: 0.4694 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5586 - accuracy: 0.8138 - val_loss: 1.2255 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.5083 - accuracy: 0.8621 - val_loss: 1.1352 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4379 - accuracy: 0.8621 - val_loss: 1.0025 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.4808 - accuracy: 0.8276 - val_loss: 1.0599 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3840 - accuracy: 0.8828 - val_loss: 1.3466 - val_accuracy: 0.4694 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3999 - accuracy: 0.8552 - val_loss: 1.2688 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3496 - accuracy: 0.9034 - val_loss: 1.1191 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3167 - accuracy: 0.9310 - val_loss: 1.1250 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2923 - accuracy: 0.9448 - val_loss: 1.1707 - val_accuracy: 0.5510 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2745 - accuracy: 0.9310 - val_loss: 1.2706 - val_accuracy: 0.5510 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2565 - accuracy: 0.9379 - val_loss: 1.2049 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2127 - accuracy: 0.9517 - val_loss: 1.1885 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2202 - accuracy: 0.9517 - val_loss: 1.2402 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1848 - accuracy: 0.9724 - val_loss: 1.3414 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1616 - accuracy: 0.9724 - val_loss: 1.2995 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1569 - accuracy: 0.9793 - val_loss: 1.2769 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1273 - accuracy: 0.9862 - val_loss: 1.3387 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.1151 - accuracy: 0.9931 - val_loss: 1.3769 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1040 - accuracy: 0.9862 - val_loss: 1.2716 - val_accuracy: 0.6122 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1328 - accuracy: 0.9655 - val_loss: 1.3385 - val_accuracy: 0.6122 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0850 - accuracy: 0.9862 - val_loss: 1.4701 - val_accuracy: 0.5510 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0659 - accuracy: 0.9931 - val_loss: 1.4666 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0817 - accuracy: 0.9862 - val_loss: 1.4264 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0745 - accuracy: 0.9862 - val_loss: 1.4923 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0604 - accuracy: 0.9931 - val_loss: 1.4790 - val_accuracy: 0.5714 - lr: 4.0000e-04\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 1.4479 - val_accuracy: 0.5510 - lr: 4.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of our model on test data : \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxVZD6q5MNLX",
        "outputId": "fc4bec68-8047-46a0-ae2e-58805db1c83d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4479 - accuracy: 0.5510\n",
            "Accuracy of our model on test data :  55.10203838348389 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=3, strides=1, activation='relu', input_shape=(40,1)))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "model.add(Conv1D(128, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "model.add(Conv1D(256, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHEZun-sMTNT",
        "outputId": "6bf8e6bc-7a05-41f3-83d1-30766a2819a9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_65 (Conv1D)          (None, 38, 64)            256       \n",
            "                                                                 \n",
            " max_pooling1d_50 (MaxPoolin  (None, 19, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_66 (Conv1D)          (None, 17, 128)           24704     \n",
            "                                                                 \n",
            " max_pooling1d_51 (MaxPoolin  (None, 8, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_67 (Conv1D)          (None, 6, 256)            98560     \n",
            "                                                                 \n",
            " max_pooling1d_52 (MaxPoolin  (None, 3, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 768)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 512)               393728    \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 519,300\n",
            "Trainable params: 519,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
        "history=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GQH2MdnNus_",
        "outputId": "82f698fa-414e-43ef-b1d5-bbc194777969"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 2s 136ms/step - loss: 1.3281 - accuracy: 0.3862 - val_loss: 1.2438 - val_accuracy: 0.3061 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.2223 - accuracy: 0.4276 - val_loss: 1.1950 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.1718 - accuracy: 0.5724 - val_loss: 1.2164 - val_accuracy: 0.3469 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.1476 - accuracy: 0.5172 - val_loss: 1.2425 - val_accuracy: 0.3469 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.0825 - accuracy: 0.5379 - val_loss: 1.2198 - val_accuracy: 0.4490 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 1.0803 - accuracy: 0.5586 - val_loss: 1.2242 - val_accuracy: 0.4286 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.0146 - accuracy: 0.5793 - val_loss: 1.1941 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.9517 - accuracy: 0.6276 - val_loss: 1.1814 - val_accuracy: 0.4490 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.9287 - accuracy: 0.6207 - val_loss: 1.2559 - val_accuracy: 0.3878 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.9263 - accuracy: 0.5862 - val_loss: 1.2410 - val_accuracy: 0.3878 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.8116 - accuracy: 0.7172 - val_loss: 1.0919 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.8009 - accuracy: 0.6276 - val_loss: 1.1138 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.7256 - accuracy: 0.7448 - val_loss: 1.2701 - val_accuracy: 0.4286 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.6466 - accuracy: 0.7931 - val_loss: 1.1583 - val_accuracy: 0.5102 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.6195 - accuracy: 0.7862 - val_loss: 1.1390 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.5619 - accuracy: 0.7931 - val_loss: 1.1815 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5214 - accuracy: 0.8138 - val_loss: 1.2305 - val_accuracy: 0.4490 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.4659 - accuracy: 0.8345 - val_loss: 1.0938 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.4136 - accuracy: 0.8552 - val_loss: 1.1445 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.3357 - accuracy: 0.8966 - val_loss: 1.3741 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.3385 - accuracy: 0.8966 - val_loss: 1.1465 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3154 - accuracy: 0.9103 - val_loss: 1.1801 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.2328 - accuracy: 0.9448 - val_loss: 1.6696 - val_accuracy: 0.5510 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.2861 - accuracy: 0.9172 - val_loss: 1.4922 - val_accuracy: 0.5510 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.1852 - accuracy: 0.9724 - val_loss: 1.3084 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.1629 - accuracy: 0.9655 - val_loss: 1.3893 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.1454 - accuracy: 0.9655 - val_loss: 1.5527 - val_accuracy: 0.5102 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.1283 - accuracy: 0.9724 - val_loss: 1.5134 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.1026 - accuracy: 0.9931 - val_loss: 1.3943 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0808 - accuracy: 0.9931 - val_loss: 1.3715 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0687 - accuracy: 0.9862 - val_loss: 1.3959 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0485 - accuracy: 0.9931 - val_loss: 1.4275 - val_accuracy: 0.5510 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0469 - accuracy: 0.9931 - val_loss: 1.4431 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0495 - accuracy: 0.9931 - val_loss: 1.5664 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 1.7278 - val_accuracy: 0.5102 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.8190 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.7751 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.8062 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.9021 - val_accuracy: 0.5510 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.8821 - val_accuracy: 0.5510 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.8186 - val_accuracy: 0.5714 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.8171 - val_accuracy: 0.5918 - lr: 4.0000e-04\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.8283 - val_accuracy: 0.5918 - lr: 4.0000e-04\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.8508 - val_accuracy: 0.5918 - lr: 4.0000e-04\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.8828 - val_accuracy: 0.5918 - lr: 4.0000e-04\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.8983 - val_accuracy: 0.5918 - lr: 1.6000e-04\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.9126 - val_accuracy: 0.5918 - lr: 1.6000e-04\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.9170 - val_accuracy: 0.5714 - lr: 6.4000e-05\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.9220 - val_accuracy: 0.5714 - lr: 6.4000e-05\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.9256 - val_accuracy: 0.5714 - lr: 6.4000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_accuracy = np.mean(history.history['accuracy'])\n",
        "print('Average Accuracy:', average_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1a7FL9rOHTS",
        "outputId": "ff8281f8-37f9-495b-c92c-0f726ddbe6c9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8554482728242874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of our model on test data : \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz1B5_K8OeHU",
        "outputId": "6a82c741-4cdb-452c-d597-deb9660be23a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 24ms/step - loss: 1.9256 - accuracy: 0.5714\n",
            "Accuracy of our model on test data :  57.14285969734192 %\n"
          ]
        }
      ]
    }
  ]
}